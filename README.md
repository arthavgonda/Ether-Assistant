<div align="center">

# ğŸ¤ EitherAssistant

**Offline-first, cross-platform voice automation framework for OS-level desktop control**

A modular system enabling real-time speech recognition, intent-driven command execution, and deterministic automation across desktop operating systems â€” with no mandatory cloud dependency.

[![Platform](https://img.shields.io/badge/Platform-Windows%20%7C%20macOS%20%7C%20Linux-blue)](https://github.com)
[![Backend](https://img.shields.io/badge/Backend-Python%203.8%2B-blue)](https://python.org)
[![Frontend](https://img.shields.io/badge/Frontend-.NET%208.0%20%7C%20Avalonia-purple)](https://dotnet.microsoft.com)
[![Architecture](https://img.shields.io/badge/Architecture-Offline--First%20%7C%20Modular-green)](#)

</div>

---

<div align="center">

**Enable OS-level desktop control through real-time voice-driven automation â€” fully functional offline.**

EitherAssistant provides an offline-first, accessibility-focused voice interface for deterministic control of applications, browsers, and system resources, designed for users with motor impairments, low-connectivity environments, and hands-free interaction workflows.


Quick Navigation : 
â€¢ [ğŸš€ Deployment Guide](#-quick-start) â€¢ [ğŸ’¬ Command Grammar](#-voice-commands) â€¢ [ğŸ“Š System Architecture](#-how-it-works) â€¢ [ğŸ”® Feature Roadmap](#-planned-improvements-for-round-2)

</div>

---

## See It In Action...

<div align="center">

### Complete Setup & Demo Video



https://github.com/user-attachments/assets/73fca6bc-e572-49d3-8705-ef38e2a9dea6



</div>

---


</div>

## Explanatory Vedio ...

<div align="center">

For a complete explanation of EitherAssistant:

ğŸ”— https://drive.google.com/drive/folders/1x7_5lAEeaOreMWTTmKOiBzdXMjcUWLdJ?usp=sharing



https://github.com/user-attachments/assets/73fca6bc-e572-49d3-8705-ef38e2a9dea6



</div>

---
## Why EitherAssistant?

<div align="center">

### The Problem
> Most existing voice assistants are architected as cloud-dependent, application-restricted systems, resulting in high latency, limited control scope, reduced reliability in low-connectivity environments, and insufficient support for accessibility-focused use cases.

### The Solution
> EitherAssistant introduces an offline-first, OS-level voice automation architecture that enables deterministic control over applications and system resources, with accessibility and privacy as first-class design constraints.

</div>

<table width = 100%>
<tr>
<td width="50%" valign = top >

#### Conventional Voice Assistants
- Cloud-centric STT and NLP pipelines  

- Mandatory continuous internet connectivity  

- Restricted to vendor-supported applications  

- Variable latency due to network round-trips  

- Audio and commands processed off-device  

- Designed primarily for general convenience  


</td>
<td width="55%" valign = top>

#### EitherAssistant
- Offline-first local speech inference  

- Fully functional without network access  

- OS- and browser-level control of any application 

- Predictable low-latency local execution  

- On-device audio and command processing 

- Accessibility-driven and privacy-first design  

- Context memory to store the user history and acitvity 


</td>
</tr>
</table>

---

## What It Does

<table>
<tr>
<td width="33%" align="center">

### ğŸ¤ Voice Control  

**Low-latency speech-to-action pipeline**

- Continuous microphone sampling at 16 kHz with real-time processing 

- Streaming speech-to-text inference with average transcription latency < 300 ms  

- Natural language command parsing and intent classification  

- Supports compound and multi-step command execution  

- Deterministic mapping of voice intents to system-level actions  

</td>
<td width="33%" align="center">

### ğŸŒ Browser Automation  
**Voice-driven browser control and interaction**

- Browser automation across Chrome, Firefox, Brave, Edge, and Chromium  

- Voice-initiated web search, URL navigation, and page traversal  

- Programmatic DOM interaction (click, type, submit)  

- Automated file downloads with execution feedback  

- No reliance on website-specific APIs or extensions  

</td>
<td width="33%" align="center">

### ğŸ’» System Control  
**Operating systemâ€“level command execution**

- Voice-based file system operations (create, move, delete, list)  

- Application lifecycle management (launch, focus, terminate)  

- System configuration controls (volume, brightness, settings access)  

- OS-specific command routing with safety validation  

- Unified abstraction for Windows, macOS, and Linux  



</td>
</tr>
<tr>
<td width="33%" align="center">

### ğŸ“± App Management  
**Context-aware multi-application workflows**

- Voice-driven application switching and focus control  

- Maintains execution context across sequential commands  

- Supports multi-application task flows (e.g., open â†’ edit â†’ save)  

- Application-agnostic control without internal API dependencies 


- State-aware command routing to the active application  

</td>
<td width="33%" align="center">

### ğŸ”‡ Offline Mode  
**Offline-first execution and inference**

- Fully local speech recognition using Vosk models (~50â€“180 MB)  

- Zero network dependency for core system functionality  

- Predictable performance and latency in offline environments  

- On-device audio processing ensuring data privacy  

- Optional online inference fallback for higher transcription accuracy  

</td>
<td width="33%" align="center">

### â™¿ Accessibility  
**Assistive computingâ€“optimized design**

- Enables 100% hands-free system interaction  

- Eliminates dependency on keyboard and pointing devices 

- Compatible with platform-native screen readers  

- Reduces cognitive and physical input load  

- Designed for users with motor  impairments  


</td>
</tr>
</table>

---

## How It Works


### System Flow

![Voice Command Flow](Diagrams/FlowChart.png)

### System Architecture

**Level 0 - System Overview**

![System DFD](Diagrams/Level_0DFD.png)

**Level 1 - Detailed Data Flow**

![Detailed DFD](Diagrams/Level_1DFD.png)

---
## ğŸš€ Quick Start
> ğŸ’¡ **Tip:** Click on arrows for full summary  .
<details>
<summary><b>ğŸ“¦ Option 1: Pre-built Binaries (Recommended)</b></summary>

### âš¡ Precompiled Distribution

Use the pre-built executables for immediate deployment without manual setup.

ğŸ‘‰ **[Detailed Installation Guide](INSTALLATION.md#-option-1-pre-built-binaries-recommended)**

1. Download the appropriate binary from the `FinalApp/` directory  
2. Execute the platform-specific binary  
3. Grant microphone permissions and begin issuing voice commands  

> Includes frontend, backend, runtime dependencies, and default configuration

</details>

<details>
<summary><b>ğŸ”§ Option 2: Build from Source</b></summary>

### ğŸ§± Source-Based Build

Compile and run the system manually for development, customization, or contribution.

ğŸ‘‰ **[Detailed Build Instructions](INSTALLATION.md#-option-2-build-from-source)**

- Requires .NET 8.0 SDK and Python 3.8+  
- Enables full access to source code and configuration  
- Recommended for developers and contributors  


</details>

### Quick Commands
Use the given Commands to compile and run Either Assistant Locally 


**Frontend:**
```bash
cd EitherAssistant
dotnet restore && dotnet build
dotnet run
```

**Backend:**
```bash
cd Python
python3 -m venv venv # Building the Virtual Environment 
source venv/bin/activate  # Windows: venv\Scripts\activate 
pip install -r requirements.txt
python3 api_server.py
```

</details>

---

### ğŸ’¬ Voice Commands

<table width = 100%>
<tr>
<td>

### ğŸ“± Applications
```bash
"Open VS Code"
"Switch to Firefox"
"Open VS Code and create file test.py"
```
-Application launch and context switching

-Supports compound commands (2â€“3 actions per utterance)
</td>
<td>

### ğŸŒ Web
```bash
"Search for Python tutorials"
"Open youtube.com"
"Download Discord"
```
-Voice-driven browser navigation and search

-Works across Chrome, Firefox, Brave, and Edge

-Automated downloads with execution feedback
</td>
</tr>

<tr>
<td>

### ğŸ“ Files
```bash
"Create file notes.txt"
"List files in Documents"
"Move file to Downloads"
```
-File system operations via OS-level automation

-Supports relative and absolute paths

-Safe execution with validation before destructive actions
</td>
<td>

### âš™ï¸ System
```bash
"System info"
"Install git"
"Volume up"
```
-System information and utility commands

-Package installation via native package managers

-Real-time control of system settings (volume, brightness)
</td>
</tr>
</table width = 100%>

> ğŸ’¡ **Tip:** Speak naturally! EitherAssistant understands conversational commands It's build just for you .

---

## ğŸ› ï¸ System Requirements

<table width = 100%>
<tr>
<td align="center">

### Operating System
- Windows 10+
- macOS 10.15+
- Linux (Ubuntu 20.04+)

</td>
<td align="center">

### Hardware
- 4GB RAM (8GB recommended)
- Microphone (required)
- Internet (optional)

</td>
<td align="center">

### Software
- Python 3.8+
- .NET 8.0 SDK
- Browser (Chrome/Firefox)

</td>
</tr>
</table width = 100%>

---
## Tech Stack

### ğŸ–¥ï¸ Frontend
- **Avalonia UI** â€” Cross-platform desktop UI framework  
- **C# / .NET 8.0** â€” Application runtime and UI logic  
- **MVVM architecture** â€” Clean separation of views, state, and logic  
- **Native accessibility APIs** â€” Screen reader and keyboard support  

---

### ğŸ§  Backend
- **Python 3.8+** â€” Core backend runtime  
- **FastAPI (ASGI)** â€” High-performance REST and WebSocket server  
- **WebSockets** â€” Low-latency, bidirectional communication  
- **Async I/O** â€” Concurrent request and audio stream handling  

---

### ğŸ¤ Speech Recognition
- **Vosk** â€” Offline, on-device speech-to-text inference  
- **Whisper** â€” Optional high-accuracy transcription  
- **Hybrid STT pipeline** â€” Automatic offline/online selection  
- **Noise reduction & VAD** â€” Improved transcription reliability  

---

### ğŸŒ Automation
- **Selenium WebDriver** â€” Browser automation and DOM interaction  
- **Cross-browser support** â€” Chrome, Firefox, Brave, Edge, Chromium  
- **OS-level commands** â€” Application and file system control  

---

### ğŸ§© Command Interpretation
- **Gemini API (optional)** â€” Natural language intent extraction  
- **Rule-based fallback parser** â€” Deterministic offline command handling  
- **Context-aware execution** â€” Supports multi-step workflows  

---

## ğŸŒ Accessibility Features

<div align="center">

| ğŸ¦½ Motor Disabilities | ğŸ‘ï¸ Visual Impairments | ğŸ“¡ Low Connectivity | ğŸ’° Cost-Free | ğŸ”„ Cross-Platform |
|:---------------------:|:---------------------:|:-------------------:|:------------:|:----------------:|
| âœ… Complete hands-free control | âœ… Screen reader compatible | âœ… Full offline functionality | âœ… Open source | âœ… Works on any device |
| No keyboard/mouse needed | Voice feedback | No internet required | No subscriptions | Windows, macOS, Linux |

</div>

---
## âœ… Planned Improvements for Round 2 â€” Completed

All improvements promised during **Round 1** have been successfully implemented and integrated into EitherAssistant for Round 2.

<table width="100%" valign = top>
<tr>
<td width="50%" valign="top">

### ğŸ§  Context Memory  
**Session-aware command continuity**

- Preserves short-term context across commands  
- Resolves references like *â€œitâ€* or *â€œthe previous appâ€*  
- Tracks active application, file, and browser state  
- Enables follow-up commands without restating intent  
- Safely expires context to prevent unintended actions  

**Technical implementation:**
- Ether-Assistant/Python/memory

**Status:** ğŸŸ¢ **Completed**

</td>
<td width="50%" valign="top">

### ğŸŒ 2. Multilingual Support
Voice input now works beyond English.

**Whatâ€™s implemented:**
- Hindi speech-to-text support  
- Foundation for regional language expansion  
- Automatic language detection  

**Status:** ğŸŸ¢ **Completed**

</td>
</tr>

<tr>
<td width="50%" valign="top">

### ğŸ› ï¸ 3. Custom Commands
Users can personalize how EitherAssistant behaves.

**Whatâ€™s implemented:**
- User-defined shortcuts  
- Workflow commands like *â€œStart work modeâ€*  
- Reusable command templates  

**Status:** âšªï¸ **Ongoing**

</td>
<td width="50%" valign="top">

### â™¿ 4. Enhanced Accessibility
Improved usability for all users.

**Whatâ€™s implemented:**
- Better screen reader compatibility  
- Voice confirmations for critical actions  
- Dedicated accessibility mode toggle  

**Status:** âšªï¸ **Ongoing*

</td>
</tr>
</table>

> ğŸš€ **Round 2 Summary:**  
> Some of the feautres said to be integrated are  fully delivered, tested, and integrated.  
> EitherAssistant is now more conversational, inclusive, customizable, and more Enhanced .


</td>
</tr>
<tr>
</td>
</tr>
</table width = 100%>

---

## Troubleshooting
> ğŸ’¡ **Tip:** Click on arrows for full summary  .
<details>
<summary><b>Audio not detected?</b></summary>

- Check microphone permissions in system settings
- Adjust sensitivity in application settings
- Test microphone: `python -m sounddevice`

</details>

<details>
<summary><b>Browser not working?</b></summary>

- Ensure Chrome, Firefox, or Brave is installed
- Check browser can run normally
- Linux: `sudo apt install chromium-browser firefox`

</details>

<details>
<summary><b>Port 8000 in use?</b></summary>

- Stop other services using port 8000
- Change port in config: `export API_PORT=8001`
- Kill process: `lsof -ti:8000 | xargs kill -9`

</details>

<details>
<summary><b>Need more help?</b></summary>

- API Documentation: `http://localhost:8000/docs`
- Create an issue on GitHub
- Check troubleshooting section above

</details>

---

## ğŸ” Privacy, Security & Reliability

EitherAssistant is designed as an **offline-first, privacy-preserving desktop automation system**, ensuring user control, data safety, and predictable behavior.

<table width="100%">
<tr>
<td width="33%" valign="top">

### ğŸ”’ Privacy
- Local audio capture and STT by default  
- No external data transmission without consent  
- No persistent audio or command storage  
- Fully functional in offline environments  

</td>
<td width="33%" valign="top">

### ğŸ›¡ï¸ Security
- User-level command execution only  
- Validation for destructive operations  
- No background network activity by default  
- Modular backend reduces failure impact  

</td>
<td width="33%" valign="top">

### âš™ï¸ Reliability
- Deterministic command execution  
- < 300 ms average local latency  
- Graceful handling of STT uncertainty  
- No cloud dependency for core features  

</td>
</tr>
</table>

This design makes EitherAssistant suitable for **assistive computing, privacy-sensitive environments, and offline-first workflows**, while maintaining system stability and user trust.


## ğŸ“š References

This project is informed by prior research, open-source documentation, and industry-standard tools related to speech recognition, accessibility, and system automation.

### ğŸ“„ Research Papers & Academic Resources
1. Radford, A. et al. *Whisper: Robust Speech Recognition via Large-Scale Weak Supervision*. OpenAI, 2022.  
2. Alpha Cephei. *Vosk Speech Recognition Toolkit*.  
3. World Health Organization. *Disability and Health*, 2023.  
4. WebAIM. *The WebAIM Million: An Annual Accessibility Analysis*, 2024.

---

### ğŸ“˜ Official Documentation
1. Avalonia UI Documentation â€” https://docs.avaloniaui.net/  
2. FastAPI Documentation â€” https://fastapi.tiangolo.com/  
3. Selenium WebDriver Documentation â€” https://www.selenium.dev/documentation/  
4. Python Documentation â€” https://docs.python.org/3/  
5. .NET 8 Documentation â€” https://learn.microsoft.com/dotnet/

---

### ğŸ§  Speech & Automation Technologies
1. OpenAI Whisper â€” https://github.com/openai/whisper  
2. Vosk API â€” https://alphacephei.com/vosk/  
3. WebRTC Voice Activity Detection â€” https://webrtc.org/  
4. PortAudio â€” http://www.portaudio.com/  

---

### â™¿ Accessibility & Standards
1. W3C Web Accessibility Initiative (WAI) â€” https://www.w3.org/WAI/  
2. WCAG 2.1 Guidelines â€” https://www.w3.org/TR/WCAG21/  
3. Assistive Technology Overview â€” https://www.w3.org/WAI/standards-guidelines/aria/

---
### ğŸ‘ï¸ Problem Related Documentation 
1. https://cra.org/crn/2020/11/expanding-the-pipeline-the-status-of-persons-with-disabilities-in-the-computer-science-pipeline/
2. https://doit.uw.edu/brief/working-together-people-with-disabilities-and-computer-technology/
3. https://www.ijert.org/research/voice-computing-technology-for-next-technical-era-IJERTV2IS120894.pdf
4. https://dl.acm.org/doi/10.1145/3626253.3635364

## ğŸ™ Acknowledgments

<div align="center">

### ğŸ§© Built with open-source technologies

<table>
<tr>
<td align="center">

ğŸ–¥ï¸ **Avalonia UI**  
Cross-platform framework

</td>
<td align="center">

âš¡ **FastAPI**  
Modern Python web framework

</td>
<td align="center">

ğŸ¤ **Whisper**  
OpenAI speech recognition

</td>
<td align="center">

ğŸ“´ **Vosk**  
Offline speech recognition

</td>
<td align="center">

ğŸŒ **Selenium**  
Browser automation

</td>
</tr>
</table>
</div>


---

## Documentation

<div align="center">



**[Download PDF â†’](https://drive.google.com/file/d/1qbPEpS_Y8iXaXrO0hxCbSktXBzcpGdYI/view?usp=share_link)**

*Comprehensive technical documentation covering architecture, implementation, and design decisions*

</div>

---

<div align="center">

[â¬† Back to Top](#-eitherassistant)

Made with â¤ï¸ for accessibility and digital inclusion

</div>

</div>
